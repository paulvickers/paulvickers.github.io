<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.1.6">Jekyll</generator><link href="https://paulvickers.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://paulvickers.github.io/" rel="alternate" type="text/html" /><updated>2017-01-19T13:09:30+00:00</updated><id>https://paulvickers.github.io/</id><title>Paul Vickers</title><subtitle>Sonification, auditory display, human-computer interaction, aesthetics, network security, visualization, digital living, computational perceptualization.</subtitle><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><entry><title>Audiogram: Embed audio in social media!</title><link href="https://paulvickers.github.io/chat/public/Audiogram-embed-audio-in-social-media/" rel="alternate" type="text/html" title="Audiogram: Embed audio in social media!" /><published>2017-01-19T00:00:00+00:00</published><updated>2017-01-19T00:00:00+00:00</updated><id>https://paulvickers.github.io/chat/public/Audiogram-embed-audio-in-social-media</id><content type="html" xml:base="https://paulvickers.github.io/chat/public/Audiogram-embed-audio-in-social-media/">&lt;p&gt;We know as sonification researchers that social media platforms prefer video over audio. This
is frustrating as we want to be able, say, to embed sonification examples in our Tweets.&lt;/p&gt;

&lt;p&gt;Well, now we can thanks to New York Public radio who have created an open source tool to 
convert audio into video which can be embedded in social media. The tool is called
&lt;a href=&quot;https://medium.com/@WNYC/socialaudio-e648e8a5f2e9#.xi3wf2nst&quot;&gt;Audiogram&lt;/a&gt; and you can get it from their &lt;a href=&quot;https://github.com/nypublicradio/audiogram&quot;&gt;git repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/DrPaulVickers/status/822066017283215361&quot;&gt;Here’s a Tweet&lt;/a&gt; with it in action.&lt;/p&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><category term="tools" /><summary>New York Public radio have created an open source tool to convert audio into video which can be embedded in social media.</summary></entry><entry><title>Sonification of protein folding</title><link href="https://paulvickers.github.io/chat/public/sonification-of-protein-folding/" rel="alternate" type="text/html" title="Sonification of protein folding" /><published>2016-10-21T00:00:00+01:00</published><updated>2016-10-21T00:00:00+01:00</updated><id>https://paulvickers.github.io/chat/public/sonification-of-protein-folding</id><content type="html" xml:base="https://paulvickers.github.io/chat/public/sonification-of-protein-folding/">&lt;p&gt;From &lt;a href=&quot;http://www.newsweek.com/new-technique-allows-scientists-listen-proteins-511840&quot;&gt;Newsweek&lt;/a&gt;: 
&amp;gt; Researchers have come up with a bold new method for representing and understanding a protein’s shape: translating it into music.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ordinarily, to show the structure of proteins—found in every cell of every living thing—scientists create visual representations made of loops and folds and sheets.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Read the full story on &lt;a href=&quot;http://www.newsweek.com/new-technique-allows-scientists-listen-proteins-511840&quot;&gt;Newsweek’s site&lt;/a&gt;.&lt;/p&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><category term="embodied computing" /><summary>&#39;Researchers have come up with a bold new method for representing and understanding a protein’s shape: translating it into music.&#39;</summary></entry><entry><title>Paul on the Sound and Data podcast</title><link href="https://paulvickers.github.io/chat/public/sound-and-data-podcast/" rel="alternate" type="text/html" title="Paul on the Sound and Data podcast" /><published>2016-07-25T00:00:00+01:00</published><updated>2016-07-25T00:00:00+01:00</updated><id>https://paulvickers.github.io/chat/public/sound-and-data-podcast</id><content type="html" xml:base="https://paulvickers.github.io/chat/public/sound-and-data-podcast/">&lt;p&gt;A little while I was interviewed by &lt;a href=&quot;http://creativedisturbance.org/people/scot-gresham-lancaster/&quot;&gt;Scot Gresham-Lancaster&lt;/a&gt; for his Sound and Data 
sonification podcast. The &lt;a href=&quot;http://creativedisturbance.org/podcast/dr-paul-vickers-sonification-ethical-computing-and-standup-comedy-eng/&quot;&gt;interview is now live&lt;/a&gt;
so I encourage you to listen to it. All feedback welcome.&lt;/p&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><category term="ethical computing" /><category term="embodied computing" /><summary>A short discussion with Dr. Vickers about his approach to sonification including some discussion of his recent standup routine regarding sonification as its main topic.</summary></entry><entry><title>Routledge Companion to Sounding Art</title><link href="https://paulvickers.github.io/news/public/sounding-art/" rel="alternate" type="text/html" title="Routledge Companion to Sounding Art" /><published>2016-07-06T00:00:00+01:00</published><updated>2016-07-06T00:00:00+01:00</updated><id>https://paulvickers.github.io/news/public/sounding-art</id><content type="html" xml:base="https://paulvickers.github.io/news/public/sounding-art/">&lt;blockquote&gt;
  &lt;p&gt;The &lt;a href=&quot;https://www.routledge.com/The-Routledge-Companion-to-Sounding-Art/Cobussen-Meelberg-Truax/p/book/9781138780613&quot;&gt;Routledge Companion to Sounding Art&lt;/a&gt;
presents an overview of the issues, methods, and approaches crucial for the study of sound in artistic practice. Thirty-six essays cover a variety of interdisciplinary approaches to studying sounding art from the fields of musicology, cultural studies, sound design, auditory culture, art history, and philosophy. The companion website hosts sound examples and links to further resources.&lt;/p&gt;

  &lt;p&gt;The collection is organized around six main themes:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;Sounding Art: The notion of sounding art, its relation to sound studies, and its evolution and possibilities.&lt;/li&gt;
    &lt;li&gt;Acoustic Knowledge and Communication: How we approach, study, and analyze sound and the challenges of writing about sound.&lt;/li&gt;
    &lt;li&gt;Listening and Memory: Listening from different perspectives, from the psychology of listening to embodied and technologically mediated listening.&lt;/li&gt;
    &lt;li&gt;Acoustic Spaces, Identities and Communities: How humans arrange their sonic environments, how this relates to sonic identity, how music contributes to our environment, and the ethical and political implications of sound.&lt;/li&gt;
    &lt;li&gt;Sound Technologies and Media: The impact of sonic technologies on contemporary culture, electroacoustic innovation, and how the way we make and access music has changed.&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;With contributions from leading scholars and cutting-edge researchers, The Routledge Companion to Sounding Art is an essential resource for anyone studying the intersection of sound and art.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><summary>The Routledge Companion to Sounding Art presents an overview of the issues, methods, and approaches crucial for the study of sound in artistic practice.</summary></entry><entry><title>Gang-gang. Beanie-counters add a new kind of beanie</title><link href="https://paulvickers.github.io/news/public/beanies/" rel="alternate" type="text/html" title="Gang-gang. Beanie-counters add a new kind of beanie" /><published>2016-07-06T00:00:00+01:00</published><updated>2016-07-06T00:00:00+01:00</updated><id>https://paulvickers.github.io/news/public/beanies</id><content type="html" xml:base="https://paulvickers.github.io/news/public/beanies/">&lt;p&gt;From the &lt;a href=&quot;http://www.canberratimes.com.au/act-news/canberra-life/ganggang-beaniecounters-add-a-new-kind-of-beanie-20160705-gpynvo.html&quot;&gt;Canberra Times&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Canberrans know that we are in midwinter, beanie-demanding, ear-protecting times. This very morning your columnist has come to work wearing with pride the swish navy blue and gold CBR Brave ice-hockey supporters’ beanie.&lt;/p&gt;

  &lt;p&gt;We don’t know how this treasured headwear was made but we are sure that its manufacture won’t compare with the ingenuity with which the beanies have been made to be handed out, at registration, to participants in this week’s annual International Conference on Auditory Display (ICAD 2016).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Read the full story on the &lt;a href=&quot;http://www.canberratimes.com.au/act-news/canberra-life/ganggang-beaniecounters-add-a-new-kind-of-beanie-20160705-gpynvo.html&quot;&gt;newspaper’s site&lt;/a&gt;.&lt;/p&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><summary>From the Canberra Times:</summary></entry><entry><title>ICAD 2016</title><link href="https://paulvickers.github.io/news/public/ICAD-2016/" rel="alternate" type="text/html" title="ICAD 2016" /><published>2016-06-23T00:00:00+01:00</published><updated>2016-06-23T00:00:00+01:00</updated><id>https://paulvickers.github.io/news/public/ICAD-2016</id><content type="html" xml:base="https://paulvickers.github.io/news/public/ICAD-2016/">&lt;p&gt;This year’s &lt;a href=&quot;http://icad.org/icad2016/&quot;&gt;International conference on Auditory Display (ICAD)&lt;/a&gt;
 is meeting in Canberra, Australia from 3-7 July. We’ve got a great programme lined up so 
 come along and hear what all the fuss is about. :-)&lt;/p&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><summary>The International Conference on Auditory Display returns to Oz</summary></entry><entry><title>Sonification in the News</title><link href="https://paulvickers.github.io/news/public/Now-hear-this/" rel="alternate" type="text/html" title="Sonification in the News" /><published>2016-03-19T00:00:00+00:00</published><updated>2016-03-19T00:00:00+00:00</updated><id>https://paulvickers.github.io/news/public/Now-hear-this</id><content type="html" xml:base="https://paulvickers.github.io/news/public/Now-hear-this/">&lt;p&gt;Sonification made it into the Economist!&lt;/p&gt;

&lt;p&gt;Jason Palmer has written a nice piece about sonification for The Economist. 
&lt;a href=&quot;http://www.economist.com/news/science-and-technology/21694992-scientific-data-might-be-filled-important-things-waiting-be-discovered&quot;&gt;Read all about it here&lt;/a&gt;&lt;/p&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><summary>Sonification made it into the Economist!</summary></entry><entry><title>Sonification Stand-up!</title><link href="https://paulvickers.github.io/chat/public/sonification-standup/" rel="alternate" type="text/html" title="Sonification Stand-up!" /><published>2014-05-28T00:00:00+01:00</published><updated>2014-05-28T00:00:00+01:00</updated><id>https://paulvickers.github.io/chat/public/sonification-standup</id><content type="html" xml:base="https://paulvickers.github.io/chat/public/sonification-standup/">&lt;p&gt;Sonification stand up!&lt;/p&gt;

&lt;p&gt;Well, I never thought I’d do this, but I performed a stand-up comedy routine (my first) on 
the subject of sonification!&lt;/p&gt;

&lt;p&gt;Just click through to &lt;a href=&quot;https://youtu.be/xfvDOmXBQuk&quot;&gt;YouTube&lt;/a&gt; to watch.&lt;/p&gt;</content><author><name>Dr Paul Vickers</name><email>paul.vickers@northumbria.ac.uk</email></author><category term="sonification" /><summary>Stand-up comedy routine on sonification at Bright Club, Newcastle, May 2014.</summary></entry></feed>
